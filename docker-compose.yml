services:

  kafka:
    build: 
      context: .
      target: kafka
    container_name: kafka
    networks:
      - kafka_network
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
      - ALLOW_PLAINTEXT_LISTENER=yes
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s

  spark-master:
    build: 
      context: .
      target: spark
    container_name: spark-master
    volumes:
      - ./requirements/kafka.txt:/opt/bitnami/spark/requirements.txt
    networks:
      - kafka_network
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-worker:
    build: 
      context: .
      target: spark
    container_name: spark-worker
    volumes:
      - ./requirements/spark.txt:/opt/bitnami/spark/requirements.txt
    depends_on:
      - spark-master
    networks:
      - kafka_network
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  webserver:
    build: 
      context: .
      target: airflow
    container_name: webserver
    command: webserver
    depends_on:
      - postgres
    networks:
      - kafka_network
    ports:
      - "8080:8080"
    volumes:
      - ./dags/:/opt/airflow/dags/
      - ./tests/:/opt/airflow/tests/
      - ./scripts/entrypoint.sh:/opt/airflow/scripts/entrypoint.sh
      - ./requirements/airflow.txt:/opt/airflow/requirements.txt
    env_file:
      - .env
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  scheduler:
    build: 
      context: .
      target: airflow
    container_name: scheduler
    depends_on:
      webserver:
        condition: service_healthy
    networks:
      - kafka_network
    volumes:
      - ./dags/:/opt/airflow/dags/
      - ./tests/:/opt/airflow/tests/
      - ./scripts/entrypoint.sh:/opt/airflow/scripts/entrypoint.sh
      - ./requirements/airflow.txt:/opt/airflow/requirements.txt
    env_file:
      - .env
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 5

  postgres:
    build: 
      context: .
      target: postgres
    container_name: postgres
    networks:
      - kafka_network
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow

networks:
  kafka_network:
    driver: bridge